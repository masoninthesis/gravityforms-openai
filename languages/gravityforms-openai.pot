# Copyright (C) 2023 Gravity Wiz
# This file is distributed under the GPL2.
msgid ""
msgstr ""
"Project-Id-Version: Gravity Forms OpenAI 1.0-beta-1.3\n"
"Report-Msgid-Bugs-To: https://wordpress.org/support/plugin/cloned-perk-HszvTeEMP\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"POT-Creation-Date: 2023-05-18T15:56:42+00:00\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"X-Generator: WP-CLI 2.7.1\n"
"X-Domain: gravityforms-openai\n"

#. Plugin Name of the plugin
msgid "Gravity Forms OpenAI"
msgstr ""

#. Plugin URI of the plugin
msgid "https://gravitywiz.com/gravity-forms-openai/"
msgstr ""

#. Description of the plugin
msgid "Pair the magic of OpenAI's robust models with Gravity Forms' flexibility."
msgstr ""

#. Author of the plugin
msgid "Gravity Wiz"
msgstr ""

#. Author URI of the plugin
msgid "https://gravitywiz.com/"
msgstr ""

#: class-gwiz-gf-openai.php:268
#: class-gwiz-gf-openai.php:307
msgid "Most capable GPT-3 model. Can do any task the other models can do, often with higher quality, longer output and better instruction-following. Also supports <a href=\"https://beta.openai.com/docs/guides/completion/inserting-text\" target=\"_blank\">inserting</a> completions within text."
msgstr ""

#: class-gwiz-gf-openai.php:272
msgid "Very capable, but faster and lower cost than Davinci."
msgstr ""

#: class-gwiz-gf-openai.php:276
msgid "Capable of straightforward tasks, very fast, and lower cost."
msgstr ""

#: class-gwiz-gf-openai.php:280
msgid "Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost."
msgstr ""

#: class-gwiz-gf-openai.php:284
#: class-gwiz-gf-openai.php:311
msgid "Most capable Codex model. Particularly good at translating natural language to code. In addition to completing code, also supports <a href=\"https://beta.openai.com/docs/guides/code/inserting-code\" target=\"_blank\">inserting</a> completions within code."
msgstr ""

#: class-gwiz-gf-openai.php:288
msgid "Almost as capable as Davinci Codex, but slightly faster. This speed advantage may make it preferable for real-time applications."
msgstr ""

#: class-gwiz-gf-openai.php:293
msgid "The same model used by <a href=\"https://chat.openai.com\" target=\"_blank\">ChatGPT</a>."
msgstr ""

#: class-gwiz-gf-openai.php:297
msgid "More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat. Will be updated with the latest model iteration.<br /><br /><a target=\"_blank\" href=\"https://openai.com/waitlist/gpt-4-api\">Join Waitlist</a>"
msgstr ""

#: class-gwiz-gf-openai.php:300
msgid "Same capabilities as the base gpt-4 mode but with 4x the context length. Will be updated with the latest model iteration.<br /><br /><a target=\"_blank\" href=\"https://openai.com/waitlist/gpt-4-api\">Join Waitlist</a>"
msgstr ""

#: class-gwiz-gf-openai.php:386
msgid "Enter your OpenAI secret key."
msgstr ""

#. translators: placeholder is a <code> element
#: class-gwiz-gf-openai.php:391
#: class-gwiz-gf-openai.php:407
msgid "Example: %s"
msgstr ""

#: class-gwiz-gf-openai.php:402
msgid "Enter your OpenAI organization if you belong to multiple."
msgstr ""

#: class-gwiz-gf-openai.php:425
msgid "Name"
msgstr ""

#: class-gwiz-gf-openai.php:426
#: class-gwiz-gf-openai.php:508
msgid "OpenAI Endpoint"
msgstr ""

#: class-gwiz-gf-openai.php:448
msgid "Given a prompt, the model will return one or more predicted completions, and can also return the probabilities of alternative tokens at each position."
msgstr ""

#: class-gwiz-gf-openai.php:449
msgid "Given a single message, the model will return a model-generated message as an output."
msgstr ""

#: class-gwiz-gf-openai.php:450
msgid "Given a prompt and an instruction, the model will return an edited version of the prompt."
msgstr ""

#: class-gwiz-gf-openai.php:451
msgid "Given a input text, outputs if the model classifies it as violating OpenAI's content policy."
msgstr ""

#: class-gwiz-gf-openai.php:478
msgid "Requires Waitlist"
msgstr ""

#: class-gwiz-gf-openai.php:502
msgid "Enter a name for this OpenAI feed. Only displayed on administrative screens."
msgstr ""

#: class-gwiz-gf-openai.php:513
msgid "Completions"
msgstr ""

#: class-gwiz-gf-openai.php:518
msgid "Chat Completions"
msgstr ""

#: class-gwiz-gf-openai.php:523
msgid "Edits"
msgstr ""

#: class-gwiz-gf-openai.php:528
msgid "Moderations"
msgstr ""

#: class-gwiz-gf-openai.php:542
#: class-gwiz-gf-openai.php:574
#: class-gwiz-gf-openai.php:606
#: class-gwiz-gf-openai.php:646
msgid "OpenAI Model"
msgstr ""

#: class-gwiz-gf-openai.php:613
msgid "The input text to use as a starting point for the edit."
msgstr ""

#: class-gwiz-gf-openai.php:621
msgid "The instruction that tells the model how to edit the prompt."
msgstr ""

#: class-gwiz-gf-openai.php:622
msgid "Instruction"
msgstr ""

#: class-gwiz-gf-openai.php:683
msgid "The validation message to display if the content policy is violated."
msgstr ""

#: class-gwiz-gf-openai.php:712
msgid "Conditional Logic"
msgstr ""

#: class-gwiz-gf-openai.php:805
msgid "Merge Tag"
msgstr ""

#: class-gwiz-gf-openai.php:806
msgid ""
"Enable getting the output of the OpenAI result using a merge tag.\n"
"\t\t\t\t\t\t\t\t<br /><br />\n"
"\t\t\t\t\t\t\t\tPro Tip: This works with Gravity Forms Populate Anything's\n"
"\t\t\t\t\t\t\t\t<a href=\"https://gravitywiz.com/documentation/gravity-forms-populate-anything/#live-merge-tags\" target=\"_blank\">Live Merge Tags</a>!"
msgstr ""

#: class-gwiz-gf-openai.php:864
msgid "Map Result to Field"
msgstr ""

#: class-gwiz-gf-openai.php:865
msgid "Take the result and attach it to a field's value upon submission."
msgstr ""

#. translators: placeholder is a number
#: class-gwiz-gf-openai.php:887
msgid "Default: <code>%d</code> seconds."
msgstr ""

#: class-gwiz-gf-openai.php:901
msgid ""
"The maximum number of <a href=\"https://beta.openai.com/tokenizer\" target=\"_blank\">tokens</a> to generate in the completion.\n"
"\t\t\t\t\t\t\t\t<br /><br />\n"
"\t\t\t\t\t\t\t\tThe token count of your prompt plus max_tokens cannot exceed the model's context\n"
"\t\t\t\t\t\t\t\tlength. Most models have a context length of 2048 tokens (except for the newest models, which support 4096)."
msgstr ""

#. translators: placeholder is a number
#: class-gwiz-gf-openai.php:911
#: class-gwiz-gf-openai.php:936
#: class-gwiz-gf-openai.php:961
#: class-gwiz-gf-openai.php:987
#: class-gwiz-gf-openai.php:1012
msgid "Default: <code>%d</code>"
msgstr ""

#: class-gwiz-gf-openai.php:925
msgid ""
"What <a href=\"https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277\" target=\"_blank\">sampling</a>\n"
"\t\t\t\t\t\t\t\ttemperature to use. Higher values means the model will take more risks. Try 0.9 for more\n"
"\t\t\t\t\t\t\t\tcreative applications, and 0 (argmax sampling) for ones with a well-defined answer.\n"
"\t\t\t\t\t\t\t\t<br /><br />\n"
"\t\t\t\t\t\t\t\tWe generally recommend altering this or <code>top_p</code> but not both."
msgstr ""

#: class-gwiz-gf-openai.php:950
msgid ""
"An alternative to sampling with temperature, called nucleus sampling,\n"
"\t\t\t\t\t\t\t\twhere the model considers the results of the tokens with top_p probability mass. So 0.1\n"
"\t\t\t\t\t\t\t\tmeans only the tokens comprising the top 10% probability mass are considered.\n"
"\t\t\t\t\t\t\t\t<br /><br />\n"
"\t\t\t\t\t\t\t\tWe generally recommend altering this or temperature but not both."
msgstr ""

#: class-gwiz-gf-openai.php:976
msgid ""
"Number between -2.0 and 2.0. Positive values penalize new tokens based\n"
"\t\t\t\t\t\t\t\ton their existing frequency in the text so far, decreasing the model's likelihood to\n"
"\t\t\t\t\t\t\t\trepeat the same line verbatim.\n"
"\t\t\t\t\t\t\t\t<br /><br />\n"
"\t\t\t\t\t\t\t\t<a href=\"https://beta.openai.com/docs/api-reference/parameter-details\" target=\"_blank\">See more information about frequency and presence penalties.</a>"
msgstr ""

#: class-gwiz-gf-openai.php:1001
msgid ""
"Number between -2.0 and 2.0. Positive values penalize new tokens based\n"
"\t\t\t\t\t\t\t\ton whether they appear in the text so far, increasing the model's likelihood to talk\n"
"\t\t\t\t\t\t\t\tabout new topics.\n"
"\t\t\t\t\t\t\t\t<br /><br />\n"
"\t\t\t\t\t\t\t\t<a href=\"https://beta.openai.com/docs/api-reference/parameter-details\" target=\"_blank\">See more information about frequency and presence penalties.</a>"
msgstr ""

#: class-gwiz-gf-openai.php:1070
msgid "Sent request to OpenAI completions endpoint."
msgstr ""

#. translators: placeholders are the feed name, model, prompt
#: class-gwiz-gf-openai.php:1073
msgid "Sent request to OpenAI. Feed: %1$s, Endpoint: completions, Model: %2$s, Prompt: %3$s"
msgstr ""

#: class-gwiz-gf-openai.php:1124
msgid "Sent request to OpenAI chat/completions endpoint."
msgstr ""

#. translators: placeholders are the feed name, model, prompt
#: class-gwiz-gf-openai.php:1127
msgid "Sent request to OpenAI. Feed: %1$s, Endpoint: chat, Model: %2$s, Message: %3$s"
msgstr ""

#: class-gwiz-gf-openai.php:1185
msgid "Sent request to OpenAI edits endpoint."
msgstr ""

#. translators: placeholders are the feed name, model, prompt
#: class-gwiz-gf-openai.php:1188
msgid "Sent request to OpenAI. Feed: %1$s, Endpoint: edits, Model: %2$s, Input: %3$s, instruction: %4$s"
msgstr ""

#. translators: placeholders are the feed name, model, and input
#: class-gwiz-gf-openai.php:1274
msgid "Sent request to OpenAI. Feed: %1$s, Endpoint: moderations, Model: %2$s, Input: %3$s"
msgstr ""

#: class-gwiz-gf-openai.php:1312
msgid "This submission violates our content policy."
msgstr ""
